{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_all_in_one.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz5QczFP0p8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "84f89e1e-6a65-4559-8e46-24998128c307"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dbYVdnmj6Ag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "eae00429-ccb8-4cba-d539-22e37198b800"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import keras\n",
        "from keras import optimizers\n",
        "\n",
        "from sys import path\n",
        "path.insert(0, '/content/drive/My Drive/KSL-translator/library/')\n",
        "\n",
        "from preprocessing import delete_face\n",
        "from preprocessing import minimize_face\n",
        "from preprocessing import split_in_blocks\n",
        "import normalization\n",
        "import augmentation\n",
        "from get_data import get_y\n",
        "import SLT_model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXaRrP6Q8x7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Useful Constants\n",
        "\n",
        "own_added = False\n",
        "\n",
        "n_steps = 50\n",
        "\n",
        "augmentation_amount = 50\n",
        "\n",
        "normalization_method = \"standard\"\n",
        "\n",
        "#0: without face, 1: minimize_face, 2:include all face points\n",
        "what_about_face = 1\n",
        "\n",
        "do_set_standard_point = False\n",
        "\n",
        "if own_added:\n",
        "  data_path = \"/content/drive/My Drive/KSL-translator/data/KETI_added_own/\"\n",
        "else:\n",
        "  data_path = \"/content/drive/My Drive/KSL-translator/data/KETI/\"\n",
        "\n",
        "X_train_path = data_path + \"X_train_og.csv\"\n",
        "X_test_path = data_path + \"X_test_og.csv\"\n",
        "\n",
        "Y_train_path = data_path + \"Y_train_amount.csv\"\n",
        "Y_test_path = data_path + \"Y_test_amount.csv\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2f7HkdILC0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = pd.read_csv(X_train_path, header=None)\n",
        "X_test = pd.read_csv(X_test_path, header=None)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_U7beAyQGnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_list = [\"file\", \"type\", \"file_name\", \"amount\", \"cumulative_sum\"]\n",
        "Y_train = pd.read_csv(Y_train_path, usecols=col_list)\n",
        "Y_test = pd.read_csv(Y_test_path, usecols=col_list)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd9zTWo2J-Wl",
        "colab_type": "text"
      },
      "source": [
        "##Without face?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktP-giTgJg8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if what_about_face == 0:\n",
        "  X_train = delete_face(X_train.values.tolist())\n",
        "  X_test = delete_face(X_test.values.tolist())\n",
        "elif what_about_face == 1:\n",
        "  X_train = minimize_face(X_train.values.tolist())\n",
        "  X_test = minimize_face(X_test.values.tolist())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv7UPXVXaMKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68c400d4-e7ca-4edb-8092-ea40a381a54f"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56910, 156)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxB4Tgh89YqE",
        "colab_type": "text"
      },
      "source": [
        "##Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRgOGrhKB7SN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalization_model_base_path = '/content/drive/My Drive/KSL-translator/model/'\n",
        "normalization_model_name = normalization_method+'_norm_model.pkl'\n",
        "\n",
        "normalization_model_path = normalization_model_base_path + normalization_model_name"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI9Etol8JJks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "724a7a0e-caa6-44cd-e3b7-3b0ef3f25f3a"
      },
      "source": [
        "X_train, X_test = normalization.norm(X_train, normalization_method, normalization_model_path, do_set_standard_point, what_about_face, X_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: []\n",
            "Index: []\n",
            "        nose_x   neck_x  r_shoulder_x  ...  r_hand_18_x  r_hand_19_x  r_hand_20_x\n",
            "0      635.232  635.284       480.521  ...      472.348      475.793      474.415\n",
            "1      635.236  635.258       480.537  ...      472.076      474.828      473.452\n",
            "2      635.258  637.193       484.382  ...      472.725      474.780      473.410\n",
            "3      635.261  637.188       482.479  ...      440.182      477.086      473.605\n",
            "4      635.263  635.322       482.438  ...      473.517      475.630      474.222\n",
            "...        ...      ...           ...  ...          ...          ...          ...\n",
            "12510  603.987  556.838       400.200  ...      321.194      324.416      336.499\n",
            "12511  604.004  556.847       400.184  ...      323.404      332.285      333.900\n",
            "12512  604.008  556.873       400.177  ...      321.636      324.850      318.421\n",
            "12513  605.835  556.824       400.170  ...      326.796      339.460      337.877\n",
            "12514  605.855  556.870       400.173  ...      332.105      341.666      336.886\n",
            "\n",
            "[12515 rows x 78 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhXX6BRXPxpU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "87e33405-acf4-41df-eb4f-598a4dbd072d"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.247602</td>\n",
              "      <td>0.372837</td>\n",
              "      <td>0.025846</td>\n",
              "      <td>0.008005</td>\n",
              "      <td>-0.648366</td>\n",
              "      <td>0.780118</td>\n",
              "      <td>0.066854</td>\n",
              "      <td>0.393147</td>\n",
              "      <td>0.283467</td>\n",
              "      <td>0.344088</td>\n",
              "      <td>0.591677</td>\n",
              "      <td>0.496120</td>\n",
              "      <td>0.315396</td>\n",
              "      <td>0.303808</td>\n",
              "      <td>0.340860</td>\n",
              "      <td>0.356394</td>\n",
              "      <td>0.351245</td>\n",
              "      <td>0.311912</td>\n",
              "      <td>0.380999</td>\n",
              "      <td>0.430540</td>\n",
              "      <td>0.418178</td>\n",
              "      <td>0.429838</td>\n",
              "      <td>0.417878</td>\n",
              "      <td>0.425589</td>\n",
              "      <td>0.257499</td>\n",
              "      <td>0.266903</td>\n",
              "      <td>0.256521</td>\n",
              "      <td>0.250217</td>\n",
              "      <td>0.274316</td>\n",
              "      <td>0.319833</td>\n",
              "      <td>0.382784</td>\n",
              "      <td>0.321511</td>\n",
              "      <td>0.270713</td>\n",
              "      <td>0.259322</td>\n",
              "      <td>0.279204</td>\n",
              "      <td>0.241684</td>\n",
              "      <td>0.449256</td>\n",
              "      <td>0.400980</td>\n",
              "      <td>0.801642</td>\n",
              "      <td>0.569385</td>\n",
              "      <td>...</td>\n",
              "      <td>0.836080</td>\n",
              "      <td>0.922847</td>\n",
              "      <td>0.903941</td>\n",
              "      <td>0.910971</td>\n",
              "      <td>0.900557</td>\n",
              "      <td>0.894822</td>\n",
              "      <td>0.930147</td>\n",
              "      <td>1.001339</td>\n",
              "      <td>0.919028</td>\n",
              "      <td>0.922918</td>\n",
              "      <td>0.924098</td>\n",
              "      <td>1.005166</td>\n",
              "      <td>0.917784</td>\n",
              "      <td>0.953275</td>\n",
              "      <td>0.941258</td>\n",
              "      <td>1.051679</td>\n",
              "      <td>0.960779</td>\n",
              "      <td>0.999973</td>\n",
              "      <td>1.009174</td>\n",
              "      <td>1.440124</td>\n",
              "      <td>1.466339</td>\n",
              "      <td>1.359404</td>\n",
              "      <td>1.323613</td>\n",
              "      <td>1.310499</td>\n",
              "      <td>1.268628</td>\n",
              "      <td>1.291854</td>\n",
              "      <td>1.297089</td>\n",
              "      <td>1.325859</td>\n",
              "      <td>1.349743</td>\n",
              "      <td>1.302790</td>\n",
              "      <td>1.302145</td>\n",
              "      <td>1.301672</td>\n",
              "      <td>1.355407</td>\n",
              "      <td>1.299774</td>\n",
              "      <td>1.310123</td>\n",
              "      <td>1.323603</td>\n",
              "      <td>1.367024</td>\n",
              "      <td>1.281771</td>\n",
              "      <td>1.376107</td>\n",
              "      <td>1.391176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.247564</td>\n",
              "      <td>0.369642</td>\n",
              "      <td>-0.021815</td>\n",
              "      <td>-0.049603</td>\n",
              "      <td>-0.648025</td>\n",
              "      <td>0.739306</td>\n",
              "      <td>0.095530</td>\n",
              "      <td>0.406668</td>\n",
              "      <td>0.283467</td>\n",
              "      <td>0.379141</td>\n",
              "      <td>0.592710</td>\n",
              "      <td>0.504687</td>\n",
              "      <td>0.303330</td>\n",
              "      <td>0.308707</td>\n",
              "      <td>0.347810</td>\n",
              "      <td>0.364924</td>\n",
              "      <td>0.358212</td>\n",
              "      <td>0.301327</td>\n",
              "      <td>0.382145</td>\n",
              "      <td>0.418302</td>\n",
              "      <td>0.422612</td>\n",
              "      <td>0.435678</td>\n",
              "      <td>0.422315</td>\n",
              "      <td>0.428621</td>\n",
              "      <td>0.233242</td>\n",
              "      <td>0.245267</td>\n",
              "      <td>0.267286</td>\n",
              "      <td>0.262134</td>\n",
              "      <td>0.287610</td>\n",
              "      <td>0.319889</td>\n",
              "      <td>0.400062</td>\n",
              "      <td>0.336833</td>\n",
              "      <td>0.284106</td>\n",
              "      <td>0.271305</td>\n",
              "      <td>0.274720</td>\n",
              "      <td>0.234938</td>\n",
              "      <td>0.462256</td>\n",
              "      <td>0.503295</td>\n",
              "      <td>0.800554</td>\n",
              "      <td>0.554843</td>\n",
              "      <td>...</td>\n",
              "      <td>0.834663</td>\n",
              "      <td>0.941097</td>\n",
              "      <td>0.896272</td>\n",
              "      <td>0.886865</td>\n",
              "      <td>0.909966</td>\n",
              "      <td>0.899526</td>\n",
              "      <td>0.934013</td>\n",
              "      <td>1.006872</td>\n",
              "      <td>0.924312</td>\n",
              "      <td>0.927209</td>\n",
              "      <td>0.936056</td>\n",
              "      <td>1.010704</td>\n",
              "      <td>0.927463</td>\n",
              "      <td>0.969673</td>\n",
              "      <td>0.961204</td>\n",
              "      <td>1.170376</td>\n",
              "      <td>1.018913</td>\n",
              "      <td>1.029008</td>\n",
              "      <td>1.025041</td>\n",
              "      <td>1.435708</td>\n",
              "      <td>1.459084</td>\n",
              "      <td>1.348267</td>\n",
              "      <td>1.312583</td>\n",
              "      <td>1.300043</td>\n",
              "      <td>1.245403</td>\n",
              "      <td>1.292647</td>\n",
              "      <td>1.286942</td>\n",
              "      <td>1.308769</td>\n",
              "      <td>1.342556</td>\n",
              "      <td>1.292012</td>\n",
              "      <td>1.288258</td>\n",
              "      <td>1.295831</td>\n",
              "      <td>1.340063</td>\n",
              "      <td>1.284902</td>\n",
              "      <td>1.304104</td>\n",
              "      <td>1.329507</td>\n",
              "      <td>1.484226</td>\n",
              "      <td>1.242318</td>\n",
              "      <td>1.398145</td>\n",
              "      <td>1.393805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.211953</td>\n",
              "      <td>0.371796</td>\n",
              "      <td>-0.022063</td>\n",
              "      <td>-0.079561</td>\n",
              "      <td>-0.647739</td>\n",
              "      <td>0.780731</td>\n",
              "      <td>0.183671</td>\n",
              "      <td>0.406225</td>\n",
              "      <td>0.246003</td>\n",
              "      <td>0.343411</td>\n",
              "      <td>0.592306</td>\n",
              "      <td>0.495900</td>\n",
              "      <td>0.294547</td>\n",
              "      <td>0.315421</td>\n",
              "      <td>0.339089</td>\n",
              "      <td>0.356182</td>\n",
              "      <td>0.349469</td>\n",
              "      <td>0.323561</td>\n",
              "      <td>0.404001</td>\n",
              "      <td>0.424859</td>\n",
              "      <td>0.413897</td>\n",
              "      <td>0.426966</td>\n",
              "      <td>0.413593</td>\n",
              "      <td>0.419906</td>\n",
              "      <td>0.240044</td>\n",
              "      <td>0.251935</td>\n",
              "      <td>0.258651</td>\n",
              "      <td>0.253554</td>\n",
              "      <td>0.263959</td>\n",
              "      <td>0.341613</td>\n",
              "      <td>0.375964</td>\n",
              "      <td>0.343407</td>\n",
              "      <td>0.260279</td>\n",
              "      <td>0.262678</td>\n",
              "      <td>0.266055</td>\n",
              "      <td>0.226187</td>\n",
              "      <td>0.470263</td>\n",
              "      <td>0.467364</td>\n",
              "      <td>0.792003</td>\n",
              "      <td>0.583051</td>\n",
              "      <td>...</td>\n",
              "      <td>0.836426</td>\n",
              "      <td>0.917322</td>\n",
              "      <td>0.889097</td>\n",
              "      <td>0.890788</td>\n",
              "      <td>0.903117</td>\n",
              "      <td>0.887991</td>\n",
              "      <td>0.909116</td>\n",
              "      <td>0.999747</td>\n",
              "      <td>0.913161</td>\n",
              "      <td>0.898316</td>\n",
              "      <td>0.910472</td>\n",
              "      <td>1.003369</td>\n",
              "      <td>0.916049</td>\n",
              "      <td>0.922866</td>\n",
              "      <td>0.930505</td>\n",
              "      <td>1.026092</td>\n",
              "      <td>0.927876</td>\n",
              "      <td>1.017261</td>\n",
              "      <td>1.025457</td>\n",
              "      <td>1.405108</td>\n",
              "      <td>1.452617</td>\n",
              "      <td>1.206855</td>\n",
              "      <td>1.286952</td>\n",
              "      <td>1.302565</td>\n",
              "      <td>1.249060</td>\n",
              "      <td>1.310240</td>\n",
              "      <td>1.310079</td>\n",
              "      <td>1.347425</td>\n",
              "      <td>1.372764</td>\n",
              "      <td>1.295230</td>\n",
              "      <td>1.335835</td>\n",
              "      <td>1.322832</td>\n",
              "      <td>1.366613</td>\n",
              "      <td>1.295659</td>\n",
              "      <td>1.328306</td>\n",
              "      <td>1.346845</td>\n",
              "      <td>1.436123</td>\n",
              "      <td>1.388606</td>\n",
              "      <td>1.388085</td>\n",
              "      <td>1.398152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.213011</td>\n",
              "      <td>0.370352</td>\n",
              "      <td>-0.022411</td>\n",
              "      <td>-0.222690</td>\n",
              "      <td>-0.539476</td>\n",
              "      <td>0.739285</td>\n",
              "      <td>0.299165</td>\n",
              "      <td>0.337830</td>\n",
              "      <td>0.282110</td>\n",
              "      <td>0.379498</td>\n",
              "      <td>0.592687</td>\n",
              "      <td>0.495991</td>\n",
              "      <td>0.310053</td>\n",
              "      <td>0.314745</td>\n",
              "      <td>0.353027</td>\n",
              "      <td>0.354141</td>\n",
              "      <td>0.363442</td>\n",
              "      <td>0.307442</td>\n",
              "      <td>0.414023</td>\n",
              "      <td>0.434238</td>\n",
              "      <td>0.422726</td>\n",
              "      <td>0.420062</td>\n",
              "      <td>0.422429</td>\n",
              "      <td>0.429288</td>\n",
              "      <td>0.223077</td>\n",
              "      <td>0.219059</td>\n",
              "      <td>0.255703</td>\n",
              "      <td>0.250160</td>\n",
              "      <td>0.260080</td>\n",
              "      <td>0.276366</td>\n",
              "      <td>0.370562</td>\n",
              "      <td>0.293022</td>\n",
              "      <td>0.256371</td>\n",
              "      <td>0.244134</td>\n",
              "      <td>0.232715</td>\n",
              "      <td>0.224144</td>\n",
              "      <td>0.465072</td>\n",
              "      <td>0.471009</td>\n",
              "      <td>0.456616</td>\n",
              "      <td>0.512352</td>\n",
              "      <td>...</td>\n",
              "      <td>0.973178</td>\n",
              "      <td>0.892795</td>\n",
              "      <td>0.860435</td>\n",
              "      <td>0.888778</td>\n",
              "      <td>0.894338</td>\n",
              "      <td>0.886155</td>\n",
              "      <td>0.890406</td>\n",
              "      <td>0.998901</td>\n",
              "      <td>0.912345</td>\n",
              "      <td>0.899582</td>\n",
              "      <td>0.902452</td>\n",
              "      <td>1.014924</td>\n",
              "      <td>0.915064</td>\n",
              "      <td>0.911186</td>\n",
              "      <td>0.975153</td>\n",
              "      <td>1.028645</td>\n",
              "      <td>0.885740</td>\n",
              "      <td>1.026144</td>\n",
              "      <td>1.033501</td>\n",
              "      <td>1.170358</td>\n",
              "      <td>1.464110</td>\n",
              "      <td>1.403898</td>\n",
              "      <td>1.291616</td>\n",
              "      <td>1.189154</td>\n",
              "      <td>1.352232</td>\n",
              "      <td>1.320631</td>\n",
              "      <td>1.114784</td>\n",
              "      <td>1.080529</td>\n",
              "      <td>1.238141</td>\n",
              "      <td>1.259234</td>\n",
              "      <td>1.196094</td>\n",
              "      <td>1.331148</td>\n",
              "      <td>1.233857</td>\n",
              "      <td>1.218616</td>\n",
              "      <td>1.254912</td>\n",
              "      <td>1.252307</td>\n",
              "      <td>1.277041</td>\n",
              "      <td>1.009758</td>\n",
              "      <td>1.264745</td>\n",
              "      <td>1.253384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.211708</td>\n",
              "      <td>0.370730</td>\n",
              "      <td>0.026566</td>\n",
              "      <td>-0.223514</td>\n",
              "      <td>-0.508166</td>\n",
              "      <td>0.738820</td>\n",
              "      <td>0.328987</td>\n",
              "      <td>0.296750</td>\n",
              "      <td>0.245334</td>\n",
              "      <td>0.378877</td>\n",
              "      <td>0.593047</td>\n",
              "      <td>0.478151</td>\n",
              "      <td>0.292565</td>\n",
              "      <td>0.297114</td>\n",
              "      <td>0.335085</td>\n",
              "      <td>0.335964</td>\n",
              "      <td>0.330074</td>\n",
              "      <td>0.289794</td>\n",
              "      <td>0.409785</td>\n",
              "      <td>0.414565</td>\n",
              "      <td>0.402841</td>\n",
              "      <td>0.415116</td>\n",
              "      <td>0.402528</td>\n",
              "      <td>0.409608</td>\n",
              "      <td>0.204918</td>\n",
              "      <td>0.200882</td>\n",
              "      <td>0.237348</td>\n",
              "      <td>0.231756</td>\n",
              "      <td>0.241476</td>\n",
              "      <td>0.272480</td>\n",
              "      <td>0.351004</td>\n",
              "      <td>0.289077</td>\n",
              "      <td>0.252747</td>\n",
              "      <td>0.240759</td>\n",
              "      <td>0.214375</td>\n",
              "      <td>0.190587</td>\n",
              "      <td>0.339099</td>\n",
              "      <td>0.593520</td>\n",
              "      <td>0.290805</td>\n",
              "      <td>0.425503</td>\n",
              "      <td>...</td>\n",
              "      <td>1.035801</td>\n",
              "      <td>0.985159</td>\n",
              "      <td>0.732614</td>\n",
              "      <td>1.014551</td>\n",
              "      <td>0.619025</td>\n",
              "      <td>0.659060</td>\n",
              "      <td>0.632825</td>\n",
              "      <td>0.882287</td>\n",
              "      <td>0.669259</td>\n",
              "      <td>0.739763</td>\n",
              "      <td>0.919963</td>\n",
              "      <td>0.888253</td>\n",
              "      <td>0.797127</td>\n",
              "      <td>0.907227</td>\n",
              "      <td>0.882608</td>\n",
              "      <td>0.850984</td>\n",
              "      <td>0.747372</td>\n",
              "      <td>0.910936</td>\n",
              "      <td>0.903205</td>\n",
              "      <td>1.046458</td>\n",
              "      <td>1.040742</td>\n",
              "      <td>0.951175</td>\n",
              "      <td>1.088758</td>\n",
              "      <td>1.350533</td>\n",
              "      <td>0.919745</td>\n",
              "      <td>1.036114</td>\n",
              "      <td>1.005622</td>\n",
              "      <td>0.966411</td>\n",
              "      <td>1.075961</td>\n",
              "      <td>1.120976</td>\n",
              "      <td>0.982234</td>\n",
              "      <td>1.088221</td>\n",
              "      <td>1.065585</td>\n",
              "      <td>1.104075</td>\n",
              "      <td>1.064387</td>\n",
              "      <td>1.056682</td>\n",
              "      <td>0.923112</td>\n",
              "      <td>0.874241</td>\n",
              "      <td>1.073695</td>\n",
              "      <td>1.063481</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 156 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       153       154       155\n",
              "0  0.247602  0.372837  0.025846  ...  1.281771  1.376107  1.391176\n",
              "1  0.247564  0.369642 -0.021815  ...  1.242318  1.398145  1.393805\n",
              "2  0.211953  0.371796 -0.022063  ...  1.388606  1.388085  1.398152\n",
              "3  0.213011  0.370352 -0.022411  ...  1.009758  1.264745  1.253384\n",
              "4  0.211708  0.370730  0.026566  ...  0.874241  1.073695  1.063481\n",
              "\n",
              "[5 rows x 156 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xK2P5mNQraw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "be5b509c-a443-46ba-ae33-bbdf0ec967b8"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "      <th>146</th>\n",
              "      <th>147</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.381338</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>-0.215587</td>\n",
              "      <td>0.151134</td>\n",
              "      <td>-0.600953</td>\n",
              "      <td>0.325349</td>\n",
              "      <td>-0.137748</td>\n",
              "      <td>0.282851</td>\n",
              "      <td>-0.331392</td>\n",
              "      <td>-0.284695</td>\n",
              "      <td>-0.067983</td>\n",
              "      <td>0.298276</td>\n",
              "      <td>-0.299881</td>\n",
              "      <td>-0.307849</td>\n",
              "      <td>-0.304166</td>\n",
              "      <td>-0.318533</td>\n",
              "      <td>-0.295376</td>\n",
              "      <td>-0.301669</td>\n",
              "      <td>-0.301882</td>\n",
              "      <td>-0.311080</td>\n",
              "      <td>-0.282514</td>\n",
              "      <td>-0.284879</td>\n",
              "      <td>-0.283388</td>\n",
              "      <td>-0.316323</td>\n",
              "      <td>-0.328109</td>\n",
              "      <td>-0.358506</td>\n",
              "      <td>-0.353123</td>\n",
              "      <td>-0.366775</td>\n",
              "      <td>-0.369351</td>\n",
              "      <td>-0.360637</td>\n",
              "      <td>-0.310521</td>\n",
              "      <td>-0.362555</td>\n",
              "      <td>-0.364325</td>\n",
              "      <td>-0.361085</td>\n",
              "      <td>-0.373075</td>\n",
              "      <td>-0.339847</td>\n",
              "      <td>0.345328</td>\n",
              "      <td>0.222695</td>\n",
              "      <td>0.452515</td>\n",
              "      <td>0.318575</td>\n",
              "      <td>...</td>\n",
              "      <td>1.076696</td>\n",
              "      <td>0.855659</td>\n",
              "      <td>0.965664</td>\n",
              "      <td>0.907355</td>\n",
              "      <td>0.905822</td>\n",
              "      <td>0.918330</td>\n",
              "      <td>0.917274</td>\n",
              "      <td>0.835793</td>\n",
              "      <td>0.866315</td>\n",
              "      <td>0.837944</td>\n",
              "      <td>0.752656</td>\n",
              "      <td>0.800979</td>\n",
              "      <td>0.829454</td>\n",
              "      <td>0.829543</td>\n",
              "      <td>0.780499</td>\n",
              "      <td>0.770683</td>\n",
              "      <td>0.764481</td>\n",
              "      <td>0.697999</td>\n",
              "      <td>0.832329</td>\n",
              "      <td>1.098275</td>\n",
              "      <td>1.077729</td>\n",
              "      <td>1.392219</td>\n",
              "      <td>1.374499</td>\n",
              "      <td>1.361936</td>\n",
              "      <td>1.271847</td>\n",
              "      <td>1.353270</td>\n",
              "      <td>1.351931</td>\n",
              "      <td>1.355079</td>\n",
              "      <td>1.210483</td>\n",
              "      <td>1.102198</td>\n",
              "      <td>1.337822</td>\n",
              "      <td>1.322574</td>\n",
              "      <td>1.229076</td>\n",
              "      <td>1.088827</td>\n",
              "      <td>0.981224</td>\n",
              "      <td>0.935512</td>\n",
              "      <td>1.232273</td>\n",
              "      <td>1.029078</td>\n",
              "      <td>0.952254</td>\n",
              "      <td>0.946004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.381262</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>-0.215190</td>\n",
              "      <td>0.151516</td>\n",
              "      <td>-0.585960</td>\n",
              "      <td>0.325074</td>\n",
              "      <td>-0.164982</td>\n",
              "      <td>0.282478</td>\n",
              "      <td>-0.331628</td>\n",
              "      <td>-0.284733</td>\n",
              "      <td>-0.067826</td>\n",
              "      <td>0.298253</td>\n",
              "      <td>-0.300075</td>\n",
              "      <td>-0.294345</td>\n",
              "      <td>-0.304320</td>\n",
              "      <td>-0.318668</td>\n",
              "      <td>-0.295530</td>\n",
              "      <td>-0.301843</td>\n",
              "      <td>-0.301940</td>\n",
              "      <td>-0.311137</td>\n",
              "      <td>-0.269042</td>\n",
              "      <td>-0.284898</td>\n",
              "      <td>-0.269904</td>\n",
              "      <td>-0.302840</td>\n",
              "      <td>-0.314407</td>\n",
              "      <td>-0.358640</td>\n",
              "      <td>-0.339733</td>\n",
              "      <td>-0.353500</td>\n",
              "      <td>-0.356076</td>\n",
              "      <td>-0.360713</td>\n",
              "      <td>-0.296978</td>\n",
              "      <td>-0.362631</td>\n",
              "      <td>-0.350950</td>\n",
              "      <td>-0.361179</td>\n",
              "      <td>-0.359659</td>\n",
              "      <td>-0.339982</td>\n",
              "      <td>0.343172</td>\n",
              "      <td>0.216650</td>\n",
              "      <td>0.436681</td>\n",
              "      <td>0.089574</td>\n",
              "      <td>...</td>\n",
              "      <td>1.069443</td>\n",
              "      <td>0.991365</td>\n",
              "      <td>0.962222</td>\n",
              "      <td>0.829533</td>\n",
              "      <td>0.901311</td>\n",
              "      <td>0.912356</td>\n",
              "      <td>0.907097</td>\n",
              "      <td>0.878614</td>\n",
              "      <td>0.833515</td>\n",
              "      <td>0.852122</td>\n",
              "      <td>0.764672</td>\n",
              "      <td>0.782790</td>\n",
              "      <td>0.819929</td>\n",
              "      <td>0.836534</td>\n",
              "      <td>0.766438</td>\n",
              "      <td>0.741358</td>\n",
              "      <td>0.764842</td>\n",
              "      <td>0.709358</td>\n",
              "      <td>0.824546</td>\n",
              "      <td>1.088244</td>\n",
              "      <td>1.202901</td>\n",
              "      <td>1.342856</td>\n",
              "      <td>1.284026</td>\n",
              "      <td>1.381410</td>\n",
              "      <td>1.269300</td>\n",
              "      <td>1.085520</td>\n",
              "      <td>1.364813</td>\n",
              "      <td>1.361678</td>\n",
              "      <td>1.204661</td>\n",
              "      <td>1.090198</td>\n",
              "      <td>1.347775</td>\n",
              "      <td>1.326135</td>\n",
              "      <td>1.213001</td>\n",
              "      <td>1.089735</td>\n",
              "      <td>0.966250</td>\n",
              "      <td>0.917621</td>\n",
              "      <td>1.202290</td>\n",
              "      <td>0.983444</td>\n",
              "      <td>0.933767</td>\n",
              "      <td>0.924394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.380847</td>\n",
              "      <td>0.045736</td>\n",
              "      <td>-0.119793</td>\n",
              "      <td>0.151707</td>\n",
              "      <td>-0.585762</td>\n",
              "      <td>0.366647</td>\n",
              "      <td>-0.136900</td>\n",
              "      <td>0.269372</td>\n",
              "      <td>-0.331353</td>\n",
              "      <td>-0.284395</td>\n",
              "      <td>-0.067354</td>\n",
              "      <td>0.298418</td>\n",
              "      <td>-0.289602</td>\n",
              "      <td>-0.311880</td>\n",
              "      <td>-0.295368</td>\n",
              "      <td>-0.310291</td>\n",
              "      <td>-0.286556</td>\n",
              "      <td>-0.305713</td>\n",
              "      <td>-0.297225</td>\n",
              "      <td>-0.307001</td>\n",
              "      <td>-0.265826</td>\n",
              "      <td>-0.282178</td>\n",
              "      <td>-0.266686</td>\n",
              "      <td>-0.298778</td>\n",
              "      <td>-0.305708</td>\n",
              "      <td>-0.350801</td>\n",
              "      <td>-0.332867</td>\n",
              "      <td>-0.360514</td>\n",
              "      <td>-0.350295</td>\n",
              "      <td>-0.355519</td>\n",
              "      <td>-0.306153</td>\n",
              "      <td>-0.357410</td>\n",
              "      <td>-0.358576</td>\n",
              "      <td>-0.354790</td>\n",
              "      <td>-0.366053</td>\n",
              "      <td>-0.332118</td>\n",
              "      <td>0.337973</td>\n",
              "      <td>0.205376</td>\n",
              "      <td>0.109180</td>\n",
              "      <td>0.091549</td>\n",
              "      <td>...</td>\n",
              "      <td>0.693503</td>\n",
              "      <td>0.771654</td>\n",
              "      <td>0.782845</td>\n",
              "      <td>0.853619</td>\n",
              "      <td>0.842274</td>\n",
              "      <td>0.859527</td>\n",
              "      <td>0.790450</td>\n",
              "      <td>0.880091</td>\n",
              "      <td>0.858972</td>\n",
              "      <td>0.797238</td>\n",
              "      <td>0.760323</td>\n",
              "      <td>0.894042</td>\n",
              "      <td>0.849249</td>\n",
              "      <td>0.777303</td>\n",
              "      <td>0.832289</td>\n",
              "      <td>0.865086</td>\n",
              "      <td>0.919382</td>\n",
              "      <td>0.870261</td>\n",
              "      <td>0.847690</td>\n",
              "      <td>1.097225</td>\n",
              "      <td>1.199971</td>\n",
              "      <td>1.335944</td>\n",
              "      <td>1.342199</td>\n",
              "      <td>1.361853</td>\n",
              "      <td>1.265997</td>\n",
              "      <td>1.328113</td>\n",
              "      <td>1.348677</td>\n",
              "      <td>1.348703</td>\n",
              "      <td>1.208267</td>\n",
              "      <td>1.081116</td>\n",
              "      <td>1.334471</td>\n",
              "      <td>1.309884</td>\n",
              "      <td>1.209860</td>\n",
              "      <td>1.096767</td>\n",
              "      <td>0.960684</td>\n",
              "      <td>0.912234</td>\n",
              "      <td>1.219546</td>\n",
              "      <td>0.977736</td>\n",
              "      <td>0.928213</td>\n",
              "      <td>0.918873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.380790</td>\n",
              "      <td>0.045617</td>\n",
              "      <td>-0.167008</td>\n",
              "      <td>0.179298</td>\n",
              "      <td>-0.570119</td>\n",
              "      <td>0.325645</td>\n",
              "      <td>-0.136216</td>\n",
              "      <td>0.269014</td>\n",
              "      <td>-0.295600</td>\n",
              "      <td>-0.284695</td>\n",
              "      <td>-0.067422</td>\n",
              "      <td>0.298404</td>\n",
              "      <td>-0.291545</td>\n",
              "      <td>-0.314716</td>\n",
              "      <td>-0.285973</td>\n",
              "      <td>-0.301780</td>\n",
              "      <td>-0.290667</td>\n",
              "      <td>-0.308558</td>\n",
              "      <td>-0.294266</td>\n",
              "      <td>-0.304904</td>\n",
              "      <td>-0.265084</td>\n",
              "      <td>-0.268901</td>\n",
              "      <td>-0.265943</td>\n",
              "      <td>-0.296795</td>\n",
              "      <td>-0.310458</td>\n",
              "      <td>-0.343096</td>\n",
              "      <td>-0.339942</td>\n",
              "      <td>-0.354971</td>\n",
              "      <td>-0.358825</td>\n",
              "      <td>-0.351784</td>\n",
              "      <td>-0.290235</td>\n",
              "      <td>-0.353656</td>\n",
              "      <td>-0.353872</td>\n",
              "      <td>-0.349215</td>\n",
              "      <td>-0.359373</td>\n",
              "      <td>-0.324389</td>\n",
              "      <td>0.332864</td>\n",
              "      <td>0.206359</td>\n",
              "      <td>0.096173</td>\n",
              "      <td>0.071626</td>\n",
              "      <td>...</td>\n",
              "      <td>0.693816</td>\n",
              "      <td>0.782480</td>\n",
              "      <td>0.764149</td>\n",
              "      <td>0.837799</td>\n",
              "      <td>0.766791</td>\n",
              "      <td>0.839165</td>\n",
              "      <td>0.924795</td>\n",
              "      <td>0.867805</td>\n",
              "      <td>0.860118</td>\n",
              "      <td>0.783159</td>\n",
              "      <td>0.761266</td>\n",
              "      <td>0.910636</td>\n",
              "      <td>0.850250</td>\n",
              "      <td>0.789667</td>\n",
              "      <td>0.819885</td>\n",
              "      <td>0.939375</td>\n",
              "      <td>0.768125</td>\n",
              "      <td>0.865110</td>\n",
              "      <td>0.853935</td>\n",
              "      <td>1.103582</td>\n",
              "      <td>1.226608</td>\n",
              "      <td>1.343998</td>\n",
              "      <td>1.330739</td>\n",
              "      <td>1.377280</td>\n",
              "      <td>1.282976</td>\n",
              "      <td>1.330127</td>\n",
              "      <td>1.354595</td>\n",
              "      <td>1.364104</td>\n",
              "      <td>1.200790</td>\n",
              "      <td>1.128072</td>\n",
              "      <td>1.343799</td>\n",
              "      <td>1.325479</td>\n",
              "      <td>1.216113</td>\n",
              "      <td>1.115069</td>\n",
              "      <td>0.964310</td>\n",
              "      <td>0.928132</td>\n",
              "      <td>1.233133</td>\n",
              "      <td>1.217045</td>\n",
              "      <td>0.951167</td>\n",
              "      <td>0.938422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.380752</td>\n",
              "      <td>0.001448</td>\n",
              "      <td>-0.168025</td>\n",
              "      <td>0.179312</td>\n",
              "      <td>-0.554897</td>\n",
              "      <td>0.325983</td>\n",
              "      <td>-0.136871</td>\n",
              "      <td>0.255557</td>\n",
              "      <td>-0.331392</td>\n",
              "      <td>-0.284564</td>\n",
              "      <td>-0.067040</td>\n",
              "      <td>0.298377</td>\n",
              "      <td>-0.281849</td>\n",
              "      <td>-0.290603</td>\n",
              "      <td>-0.301317</td>\n",
              "      <td>-0.316261</td>\n",
              "      <td>-0.292520</td>\n",
              "      <td>-0.284369</td>\n",
              "      <td>-0.303238</td>\n",
              "      <td>-0.299547</td>\n",
              "      <td>-0.271839</td>\n",
              "      <td>-0.274779</td>\n",
              "      <td>-0.272704</td>\n",
              "      <td>-0.291322</td>\n",
              "      <td>-0.311749</td>\n",
              "      <td>-0.343192</td>\n",
              "      <td>-0.338801</td>\n",
              "      <td>-0.353085</td>\n",
              "      <td>-0.356189</td>\n",
              "      <td>-0.361471</td>\n",
              "      <td>-0.298663</td>\n",
              "      <td>-0.363393</td>\n",
              "      <td>-0.351121</td>\n",
              "      <td>-0.347319</td>\n",
              "      <td>-0.345041</td>\n",
              "      <td>-0.338093</td>\n",
              "      <td>0.341407</td>\n",
              "      <td>0.216858</td>\n",
              "      <td>0.092462</td>\n",
              "      <td>0.068783</td>\n",
              "      <td>...</td>\n",
              "      <td>0.682411</td>\n",
              "      <td>0.781800</td>\n",
              "      <td>0.759443</td>\n",
              "      <td>0.844791</td>\n",
              "      <td>0.762265</td>\n",
              "      <td>0.844920</td>\n",
              "      <td>0.925816</td>\n",
              "      <td>0.891047</td>\n",
              "      <td>0.854763</td>\n",
              "      <td>0.781854</td>\n",
              "      <td>0.756221</td>\n",
              "      <td>0.913437</td>\n",
              "      <td>0.840976</td>\n",
              "      <td>0.792009</td>\n",
              "      <td>0.814209</td>\n",
              "      <td>0.703252</td>\n",
              "      <td>0.771529</td>\n",
              "      <td>0.863049</td>\n",
              "      <td>0.851890</td>\n",
              "      <td>1.094585</td>\n",
              "      <td>1.078934</td>\n",
              "      <td>1.350454</td>\n",
              "      <td>1.260568</td>\n",
              "      <td>1.306815</td>\n",
              "      <td>1.282247</td>\n",
              "      <td>1.327030</td>\n",
              "      <td>1.364868</td>\n",
              "      <td>1.368241</td>\n",
              "      <td>1.198801</td>\n",
              "      <td>1.112690</td>\n",
              "      <td>1.351135</td>\n",
              "      <td>1.329668</td>\n",
              "      <td>1.210915</td>\n",
              "      <td>1.096058</td>\n",
              "      <td>0.961036</td>\n",
              "      <td>0.921538</td>\n",
              "      <td>1.186172</td>\n",
              "      <td>1.031914</td>\n",
              "      <td>0.934410</td>\n",
              "      <td>0.928338</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 156 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2    ...       153       154       155\n",
              "0 -0.381338  0.000549 -0.215587  ...  1.029078  0.952254  0.946004\n",
              "1 -0.381262 -0.000066 -0.215190  ...  0.983444  0.933767  0.924394\n",
              "2 -0.380847  0.045736 -0.119793  ...  0.977736  0.928213  0.918873\n",
              "3 -0.380790  0.045617 -0.167008  ...  1.217045  0.951167  0.938422\n",
              "4 -0.380752  0.001448 -0.168025  ...  1.031914  0.934410  0.928338\n",
              "\n",
              "[5 rows x 156 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9e5_rsXBZZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b8430c9-10aa-48e5-e64c-cf3eb80570dd"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((56910, 156), (12515, 156))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xd5ZnOJ-xnr",
        "colab_type": "text"
      },
      "source": [
        "##Frame skip augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E8v_OysJKO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86640986-9b42-4a9b-fdaa-9b1a49ede87e"
      },
      "source": [
        "Y = augmentation.get_augment_index(Y_train, augmentation_amount-1, n_steps)\n",
        "X_np_train = augmentation.index_to_list(X_train.values.tolist(), Y, n_steps)\n",
        "\n",
        "Y = augmentation.get_augment_index(Y_test, augmentation_amount-1, n_steps)\n",
        "X_np_test = augmentation.index_to_list(X_test.values.tolist(), Y, n_steps)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90 th video : hit the limit!\n",
            "220 th video : hit the limit!\n",
            "237 th video : hit the limit!\n",
            "245 th video : hit the limit!\n",
            "250 th video : hit the limit!\n",
            "293 th video : hit the limit!\n",
            "298 th video : hit the limit!\n",
            "325 th video : hit the limit!\n",
            "329 th video : hit the limit!\n",
            "419 th video : hit the limit!\n",
            "454 th video : hit the limit!\n",
            "464 th video : hit the limit!\n",
            "493 th video : hit the limit!\n",
            "less than  50 !\n",
            "94 43\n",
            "94 baseline error! 21\n",
            "these indexes will be added [1, 4, 13, 14, 33, 34, 35]\n",
            "result :  [8298 8299 8299 8300 8301 8301 8302 8303 8304 8305 8306 8307 8308 8309\n",
            " 8309 8309 8310 8311 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321\n",
            " 8322 8323 8324 8325 8326 8327 8327 8327 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [5, 22, 29, 35, 36, 37, 40]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8303 8304 8305 8306 8307 8308 8309 8310\n",
            " 8311 8312 8313 8314 8315 8316 8317 8318 8319 8319 8320 8321 8322 8323\n",
            " 8324 8325 8325 8326 8327 8328 8329 8330 8330 8330 8330 8331 8332 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [4, 6, 16, 17, 30, 40, 41]\n",
            "result :  [8298 8299 8300 8301 8302 8302 8303 8303 8304 8305 8306 8307 8308 8309\n",
            " 8310 8311 8312 8312 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321\n",
            " 8322 8323 8324 8324 8325 8326 8327 8328 8329 8330 8331 8332 8333 8333\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [10, 19, 23, 25, 34, 39, 41]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8308 8309 8310\n",
            " 8311 8312 8313 8314 8315 8316 8316 8317 8318 8319 8319 8320 8320 8321\n",
            " 8322 8323 8324 8325 8326 8327 8328 8328 8329 8330 8331 8332 8332 8333\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [3, 9, 20, 22, 27, 28, 31]\n",
            "result :  [8298 8299 8300 8301 8301 8302 8303 8304 8305 8306 8306 8307 8308 8309\n",
            " 8310 8311 8312 8313 8314 8315 8316 8316 8317 8317 8318 8319 8320 8321\n",
            " 8321 8321 8322 8323 8323 8324 8325 8326 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [4, 5, 17, 21, 23, 27, 35]\n",
            "result :  [8298 8299 8300 8301 8302 8302 8302 8303 8304 8305 8306 8307 8308 8309\n",
            " 8310 8311 8312 8313 8313 8314 8315 8316 8316 8317 8317 8318 8319 8320\n",
            " 8320 8321 8322 8323 8324 8325 8326 8327 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [8, 19, 21, 25, 27, 30, 36]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8306 8307 8308 8309 8310\n",
            " 8311 8312 8313 8314 8315 8316 8316 8317 8317 8318 8319 8320 8320 8321\n",
            " 8321 8322 8323 8323 8324 8325 8326 8327 8328 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [13, 16, 18, 27, 29, 41, 42]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8309 8310 8311\n",
            " 8311 8312 8313 8313 8314 8314 8315 8316 8317 8318 8319 8320 8321 8322\n",
            " 8322 8323 8323 8324 8325 8326 8327 8328 8329 8330 8331 8332 8333 8334\n",
            " 8334 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [3, 8, 12, 17, 21, 32, 41]\n",
            "result :  [8298 8299 8300 8301 8301 8302 8303 8304 8305 8305 8306 8307 8308 8308\n",
            " 8309 8310 8311 8312 8312 8313 8314 8315 8315 8316 8317 8318 8319 8320\n",
            " 8321 8322 8323 8324 8325 8325 8326 8327 8328 8329 8330 8331 8332 8333\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [7, 13, 24, 25, 31, 37, 38]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8305 8306 8307 8308 8309 8310\n",
            " 8310 8311 8312 8313 8314 8315 8316 8317 8318 8319 8320 8320 8320 8321\n",
            " 8322 8323 8324 8325 8325 8326 8327 8328 8329 8330 8330 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [3, 14, 15, 28, 31, 33, 36]\n",
            "result :  [8298 8299 8300 8301 8301 8302 8303 8304 8305 8306 8307 8308 8309 8310\n",
            " 8311 8311 8311 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321 8322\n",
            " 8323 8323 8324 8325 8325 8326 8326 8327 8328 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [1, 12, 13, 20, 26, 30, 33]\n",
            "result :  [8298 8299 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8309 8309\n",
            " 8309 8310 8311 8312 8313 8314 8315 8315 8316 8317 8318 8319 8320 8320\n",
            " 8321 8322 8323 8323 8324 8325 8325 8326 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [1, 22, 25, 27, 36, 39, 40]\n",
            "result :  [8298 8299 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8309 8310\n",
            " 8311 8312 8313 8314 8315 8316 8317 8318 8319 8319 8320 8321 8321 8322\n",
            " 8322 8323 8324 8325 8326 8327 8328 8329 8330 8330 8331 8332 8332 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [10, 11, 14, 21, 28, 36, 42]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8308 8308 8309\n",
            " 8310 8310 8311 8312 8313 8314 8315 8316 8316 8317 8318 8319 8320 8321\n",
            " 8322 8322 8323 8324 8325 8326 8327 8328 8329 8329 8330 8331 8332 8333\n",
            " 8334 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [5, 6, 14, 16, 24, 27, 29]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8303 8303 8304 8305 8306 8307 8308 8309\n",
            " 8310 8310 8311 8311 8312 8313 8314 8315 8316 8317 8318 8318 8319 8320\n",
            " 8320 8321 8321 8322 8323 8324 8325 8326 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [10, 12, 21, 23, 24, 29, 36]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8308 8309 8309\n",
            " 8310 8311 8312 8313 8314 8315 8316 8317 8317 8318 8318 8318 8319 8320\n",
            " 8321 8322 8322 8323 8324 8325 8326 8327 8328 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [5, 12, 20, 28, 29, 34, 40]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8303 8304 8305 8306 8307 8308 8309 8309\n",
            " 8310 8311 8312 8313 8314 8315 8316 8316 8317 8318 8319 8320 8321 8322\n",
            " 8323 8323 8323 8324 8325 8326 8327 8327 8328 8329 8330 8331 8332 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [10, 14, 17, 25, 29, 37, 42]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8308 8309 8310\n",
            " 8311 8311 8312 8313 8313 8314 8315 8316 8317 8318 8319 8320 8320 8321\n",
            " 8322 8323 8323 8324 8325 8326 8327 8328 8329 8330 8330 8331 8332 8333\n",
            " 8334 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [23, 25, 26, 27, 29, 30, 37]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8309 8310 8311\n",
            " 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321 8321 8322 8322 8322\n",
            " 8322 8323 8323 8323 8324 8325 8326 8327 8328 8329 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [11, 13, 16, 17, 18, 25, 38]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8309 8309 8310\n",
            " 8310 8311 8312 8312 8312 8312 8313 8314 8315 8316 8317 8318 8318 8319\n",
            " 8320 8321 8322 8323 8324 8325 8326 8327 8328 8329 8330 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [0, 11, 25, 26, 29, 35, 37]\n",
            "result :  [8298 8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8308 8309\n",
            " 8310 8311 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321 8321 8321\n",
            " 8322 8323 8323 8324 8325 8326 8327 8328 8328 8329 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [5, 10, 14, 19, 25, 26, 32]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8303 8304 8305 8306 8307 8307 8308 8309\n",
            " 8310 8310 8311 8312 8313 8314 8314 8315 8316 8317 8318 8319 8319 8319\n",
            " 8320 8321 8322 8323 8324 8324 8325 8326 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [3, 5, 12, 17, 24, 32, 35]\n",
            "result :  [8298 8299 8300 8301 8301 8302 8302 8303 8304 8305 8306 8307 8308 8308\n",
            " 8309 8310 8311 8312 8312 8313 8314 8315 8316 8317 8318 8318 8319 8320\n",
            " 8321 8322 8323 8324 8325 8325 8326 8327 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [0, 6, 11, 14, 28, 32, 35]\n",
            "result :  [8298 8298 8299 8300 8301 8302 8303 8303 8304 8305 8306 8307 8307 8308\n",
            " 8309 8309 8310 8311 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321\n",
            " 8322 8322 8323 8324 8325 8325 8326 8327 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [3, 12, 16, 18, 19, 31, 35]\n",
            "result :  [8298 8299 8300 8301 8301 8302 8303 8304 8305 8306 8307 8308 8309 8309\n",
            " 8310 8311 8312 8312 8313 8313 8313 8314 8315 8316 8317 8318 8319 8320\n",
            " 8321 8322 8323 8324 8324 8325 8326 8327 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [11, 13, 15, 17, 27, 28, 32]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8309 8309 8310\n",
            " 8310 8311 8311 8312 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321\n",
            " 8321 8321 8322 8323 8324 8324 8325 8326 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [0, 7, 17, 18, 35, 37, 38]\n",
            "result :  [8298 8298 8299 8300 8301 8302 8303 8304 8304 8305 8306 8307 8308 8309\n",
            " 8310 8311 8312 8313 8313 8313 8314 8315 8316 8317 8318 8319 8320 8321\n",
            " 8322 8323 8324 8325 8326 8327 8328 8329 8329 8330 8330 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [7, 10, 12, 15, 34, 40, 41]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8305 8306 8307 8307 8308 8308\n",
            " 8309 8310 8310 8311 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321\n",
            " 8322 8323 8324 8325 8326 8327 8328 8328 8329 8330 8331 8332 8333 8333\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [3, 4, 16, 18, 31, 36, 38]\n",
            "result :  [8298 8299 8300 8301 8301 8301 8302 8303 8304 8305 8306 8307 8308 8309\n",
            " 8310 8311 8312 8312 8313 8313 8314 8315 8316 8317 8318 8319 8320 8321\n",
            " 8322 8323 8324 8325 8325 8326 8327 8328 8329 8329 8330 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [3, 13, 22, 24, 25, 35, 39]\n",
            "result :  [8298 8299 8300 8301 8301 8302 8303 8304 8305 8306 8307 8308 8309 8310\n",
            " 8310 8311 8312 8313 8314 8315 8316 8317 8318 8318 8319 8319 8319 8320\n",
            " 8321 8322 8323 8324 8325 8326 8327 8328 8328 8329 8330 8331 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [5, 12, 16, 19, 26, 33, 35]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8303 8304 8305 8306 8307 8308 8309 8309\n",
            " 8310 8311 8312 8312 8313 8314 8314 8315 8316 8317 8318 8319 8320 8320\n",
            " 8321 8322 8323 8324 8325 8326 8326 8327 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [4, 8, 13, 19, 24, 40, 42]\n",
            "result :  [8298 8299 8300 8301 8302 8302 8303 8304 8305 8305 8306 8307 8308 8309\n",
            " 8309 8310 8311 8312 8313 8314 8314 8315 8316 8317 8318 8318 8319 8320\n",
            " 8321 8322 8323 8324 8325 8326 8327 8328 8329 8330 8331 8332 8333 8333\n",
            " 8334 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [3, 15, 16, 25, 26, 38, 40]\n",
            "result :  [8298 8299 8300 8301 8301 8302 8303 8304 8305 8306 8307 8308 8309 8310\n",
            " 8311 8312 8312 8312 8313 8314 8315 8316 8317 8318 8319 8320 8320 8320\n",
            " 8321 8322 8323 8324 8325 8326 8327 8328 8329 8330 8331 8331 8332 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [10, 14, 18, 20, 24, 29, 38]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8308 8309 8310\n",
            " 8311 8311 8312 8313 8314 8314 8315 8315 8316 8317 8318 8318 8319 8320\n",
            " 8321 8322 8322 8323 8324 8325 8326 8327 8328 8329 8330 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [6, 7, 18, 23, 31, 37, 42]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8304 8304 8305 8306 8307 8308 8309\n",
            " 8310 8311 8312 8313 8314 8314 8315 8316 8317 8318 8318 8319 8320 8321\n",
            " 8322 8323 8324 8325 8325 8326 8327 8328 8329 8330 8330 8331 8332 8333\n",
            " 8334 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [0, 4, 11, 12, 16, 18, 28]\n",
            "result :  [8298 8298 8299 8300 8301 8301 8302 8303 8304 8305 8306 8307 8307 8307\n",
            " 8308 8309 8310 8310 8311 8311 8312 8313 8314 8315 8316 8317 8318 8319\n",
            " 8320 8320 8321 8322 8323 8324 8325 8326 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [7, 21, 25, 27, 29, 37, 40]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8305 8306 8307 8308 8309 8310\n",
            " 8311 8312 8313 8314 8315 8316 8317 8318 8318 8319 8320 8321 8321 8322\n",
            " 8322 8323 8323 8324 8325 8326 8327 8328 8329 8330 8330 8331 8332 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [0, 18, 24, 34, 37, 40, 42]\n",
            "result :  [8298 8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8309 8310\n",
            " 8311 8312 8313 8314 8315 8315 8316 8317 8318 8319 8320 8320 8321 8322\n",
            " 8323 8324 8325 8326 8327 8328 8329 8329 8330 8331 8331 8332 8333 8333\n",
            " 8334 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [11, 25, 30, 34, 35, 36, 38]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8309 8309 8310\n",
            " 8311 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321 8322 8322 8323\n",
            " 8324 8325 8326 8326 8327 8328 8329 8329 8329 8329 8330 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [0, 10, 14, 16, 20, 22, 33]\n",
            "result :  [8298 8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8307 8308 8309\n",
            " 8310 8310 8311 8311 8312 8313 8314 8314 8315 8315 8316 8317 8318 8319\n",
            " 8320 8321 8322 8323 8324 8325 8325 8326 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [1, 7, 16, 24, 28, 36, 42]\n",
            "result :  [8298 8299 8299 8300 8301 8302 8303 8304 8304 8305 8306 8307 8308 8309\n",
            " 8310 8311 8312 8312 8313 8314 8315 8316 8317 8318 8319 8319 8320 8321\n",
            " 8322 8322 8323 8324 8325 8326 8327 8328 8329 8329 8330 8331 8332 8333\n",
            " 8334 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [6, 9, 11, 15, 17, 25, 31]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8304 8305 8306 8306 8307 8307 8308\n",
            " 8309 8310 8310 8311 8311 8312 8313 8314 8315 8316 8317 8318 8318 8319\n",
            " 8320 8321 8322 8323 8323 8324 8325 8326 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [11, 20, 22, 27, 29, 40, 42]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8309 8309 8310\n",
            " 8311 8312 8313 8314 8315 8316 8317 8317 8318 8318 8319 8320 8321 8322\n",
            " 8322 8323 8323 8324 8325 8326 8327 8328 8329 8330 8331 8332 8333 8333\n",
            " 8334 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [0, 3, 17, 22, 33, 34, 38]\n",
            "result :  [8298 8298 8299 8300 8300 8301 8302 8303 8304 8305 8306 8307 8308 8309\n",
            " 8310 8311 8312 8313 8313 8314 8315 8316 8317 8317 8318 8319 8320 8321\n",
            " 8322 8323 8324 8325 8326 8327 8327 8327 8328 8329 8330 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [2, 6, 9, 13, 23, 29, 36]\n",
            "result :  [8298 8299 8300 8300 8301 8302 8303 8303 8304 8305 8305 8306 8307 8308\n",
            " 8308 8309 8310 8311 8312 8313 8314 8315 8316 8317 8317 8318 8319 8320\n",
            " 8321 8322 8322 8323 8324 8325 8326 8327 8328 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [6, 9, 13, 14, 31, 33, 42]\n",
            "result :  [8298 8299 8300 8301 8302 8303 8304 8304 8305 8306 8306 8307 8308 8309\n",
            " 8309 8309 8310 8311 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321\n",
            " 8322 8323 8324 8325 8325 8326 8326 8327 8328 8329 8330 8331 8332 8333\n",
            " 8334 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [4, 8, 10, 14, 16, 19, 32]\n",
            "result :  [8298 8299 8300 8301 8302 8302 8303 8304 8305 8305 8306 8306 8307 8308\n",
            " 8309 8309 8310 8310 8311 8312 8312 8313 8314 8315 8316 8317 8318 8319\n",
            " 8320 8321 8322 8323 8324 8324 8325 8326 8327 8328 8329 8330 8331 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [1, 13, 27, 28, 35, 37, 41]\n",
            "result :  [8298 8299 8299 8300 8301 8302 8303 8304 8305 8306 8307 8308 8309 8310\n",
            " 8310 8311 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321 8322 8323\n",
            " 8323 8323 8324 8325 8326 8327 8328 8329 8329 8330 8330 8331 8332 8333\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "these indexes will be added [4, 11, 13, 17, 37, 39, 40]\n",
            "result :  [8298 8299 8300 8301 8302 8302 8303 8304 8305 8306 8307 8308 8308 8309\n",
            " 8309 8310 8311 8312 8312 8313 8314 8315 8316 8317 8318 8319 8320 8321\n",
            " 8322 8323 8324 8325 8326 8327 8328 8329 8330 8331 8331 8332 8332 8332\n",
            " 8333 8334 8335 8336 8337 8338 8339 8340]\n",
            "less than  50 !\n",
            "95 44\n",
            "95 baseline error! 22\n",
            "these indexes will be added [9, 15, 18, 21, 32, 40]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8350 8351 8352 8353\n",
            " 8354 8355 8355 8356 8357 8357 8358 8359 8359 8360 8361 8362 8363 8364\n",
            " 8365 8366 8367 8368 8369 8369 8370 8371 8372 8373 8374 8375 8376 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [8, 20, 24, 30, 40, 42]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8349 8350 8351 8352 8353\n",
            " 8354 8355 8356 8357 8358 8359 8360 8360 8361 8362 8363 8363 8364 8365\n",
            " 8366 8367 8368 8368 8369 8370 8371 8372 8373 8374 8375 8376 8377 8377\n",
            " 8378 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [9, 14, 16, 17, 25, 36]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8350 8351 8352 8353\n",
            " 8354 8354 8355 8355 8355 8356 8357 8358 8359 8360 8361 8362 8362 8363\n",
            " 8364 8365 8366 8367 8368 8369 8370 8371 8372 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [7, 14, 22, 31, 36, 38]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8348 8349 8350 8351 8352 8353\n",
            " 8354 8354 8355 8356 8357 8358 8359 8360 8361 8361 8362 8363 8364 8365\n",
            " 8366 8367 8368 8369 8369 8370 8371 8372 8373 8373 8374 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [0, 3, 22, 31, 35, 37]\n",
            "result :  [8341 8341 8342 8343 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352\n",
            " 8353 8354 8355 8356 8357 8358 8359 8360 8361 8361 8362 8363 8364 8365\n",
            " 8366 8367 8368 8369 8369 8370 8371 8372 8372 8373 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [15, 16, 21, 30, 34, 35]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353 8354\n",
            " 8355 8356 8356 8356 8357 8358 8359 8360 8360 8361 8362 8363 8364 8365\n",
            " 8366 8367 8368 8368 8369 8370 8371 8371 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [2, 16, 24, 26, 27, 32]\n",
            "result :  [8341 8342 8343 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353\n",
            " 8354 8355 8356 8356 8357 8358 8359 8360 8361 8362 8363 8363 8364 8364\n",
            " 8364 8365 8366 8367 8368 8368 8369 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [7, 14, 16, 18, 28, 37]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8348 8349 8350 8351 8352 8353\n",
            " 8354 8354 8355 8355 8356 8356 8357 8358 8359 8360 8361 8362 8363 8364\n",
            " 8365 8365 8366 8367 8368 8369 8370 8371 8372 8373 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [0, 10, 12, 14, 19, 37]\n",
            "result :  [8341 8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8350 8351 8351\n",
            " 8352 8352 8353 8354 8355 8356 8356 8357 8358 8359 8360 8361 8362 8363\n",
            " 8364 8365 8366 8367 8368 8369 8370 8371 8372 8373 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [0, 6, 18, 19, 27, 29]\n",
            "result :  [8341 8341 8342 8343 8344 8345 8346 8346 8347 8348 8349 8350 8351 8352\n",
            " 8353 8354 8355 8356 8357 8357 8357 8358 8359 8360 8361 8362 8363 8364\n",
            " 8364 8365 8365 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [3, 8, 17, 21, 36, 43]\n",
            "result :  [8341 8342 8343 8344 8344 8345 8346 8347 8348 8348 8349 8350 8351 8352\n",
            " 8353 8354 8355 8356 8356 8357 8358 8359 8359 8360 8361 8362 8363 8364\n",
            " 8365 8366 8367 8368 8369 8370 8371 8372 8373 8373 8374 8375 8376 8377\n",
            " 8378 8379 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [2, 3, 5, 6, 15, 17]\n",
            "result :  [8341 8342 8343 8343 8343 8344 8344 8344 8345 8346 8347 8348 8349 8350\n",
            " 8351 8352 8352 8353 8353 8354 8355 8356 8357 8358 8359 8360 8361 8362\n",
            " 8363 8364 8365 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [9, 10, 17, 21, 26, 37]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8350 8350 8351 8352\n",
            " 8353 8354 8355 8356 8356 8357 8358 8359 8359 8360 8361 8362 8363 8363\n",
            " 8364 8365 8366 8367 8368 8369 8370 8371 8372 8373 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [0, 14, 21, 37, 38, 39]\n",
            "result :  [8341 8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353\n",
            " 8354 8354 8355 8356 8357 8358 8359 8360 8360 8361 8362 8363 8364 8365\n",
            " 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8375 8375 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [3, 6, 14, 22, 32, 42]\n",
            "result :  [8341 8342 8343 8344 8344 8345 8346 8346 8347 8348 8349 8350 8351 8352\n",
            " 8353 8353 8354 8355 8356 8357 8358 8359 8360 8360 8361 8362 8363 8364\n",
            " 8365 8366 8367 8368 8369 8369 8370 8371 8372 8373 8374 8375 8376 8377\n",
            " 8378 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [4, 13, 26, 28, 31, 36]\n",
            "result :  [8341 8342 8343 8344 8345 8345 8346 8347 8348 8349 8350 8351 8352 8353\n",
            " 8353 8354 8355 8356 8357 8358 8359 8360 8361 8362 8363 8364 8365 8365\n",
            " 8366 8366 8367 8368 8368 8369 8370 8371 8372 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [18, 24, 26, 32, 37, 42]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353 8354\n",
            " 8355 8356 8357 8358 8359 8359 8360 8361 8362 8363 8364 8364 8365 8365\n",
            " 8366 8367 8368 8369 8370 8370 8371 8372 8373 8374 8374 8375 8376 8377\n",
            " 8378 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [22, 23, 25, 29, 39, 42]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353 8354\n",
            " 8355 8356 8357 8358 8359 8360 8361 8362 8363 8363 8363 8364 8364 8365\n",
            " 8366 8367 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376 8376 8377\n",
            " 8378 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [0, 2, 9, 10, 14, 26]\n",
            "result :  [8341 8341 8342 8342 8343 8344 8345 8346 8347 8348 8348 8348 8349 8350\n",
            " 8351 8351 8352 8353 8354 8355 8356 8357 8358 8359 8360 8361 8362 8362\n",
            " 8363 8364 8365 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [9, 12, 20, 21, 30, 31]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8350 8351 8352 8352\n",
            " 8353 8354 8355 8356 8357 8358 8359 8359 8359 8360 8361 8362 8363 8364\n",
            " 8365 8366 8367 8367 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [8, 9, 22, 36, 37, 42]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8349 8349 8350 8351 8352\n",
            " 8353 8354 8355 8356 8357 8358 8359 8360 8361 8361 8362 8363 8364 8365\n",
            " 8366 8367 8368 8369 8370 8371 8372 8373 8374 8374 8374 8375 8376 8377\n",
            " 8378 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [2, 6, 26, 31, 34, 40]\n",
            "result :  [8341 8342 8343 8343 8344 8345 8346 8346 8347 8348 8349 8350 8351 8352\n",
            " 8353 8354 8355 8356 8357 8358 8359 8360 8361 8362 8363 8364 8365 8365\n",
            " 8366 8367 8368 8369 8369 8370 8371 8371 8372 8373 8374 8375 8376 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [10, 14, 16, 32, 37, 43]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8351 8352 8353\n",
            " 8354 8354 8355 8355 8356 8357 8358 8359 8360 8361 8362 8363 8364 8365\n",
            " 8366 8367 8368 8369 8370 8370 8371 8372 8373 8374 8374 8375 8376 8377\n",
            " 8378 8379 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [3, 7, 9, 15, 24, 41]\n",
            "result :  [8341 8342 8343 8344 8344 8345 8346 8347 8347 8348 8348 8349 8350 8351\n",
            " 8352 8353 8353 8354 8355 8356 8357 8358 8359 8360 8361 8361 8362 8363\n",
            " 8364 8365 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376 8377\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [1, 4, 23, 24, 29, 33]\n",
            "result :  [8341 8342 8342 8343 8344 8344 8345 8346 8347 8348 8349 8350 8351 8352\n",
            " 8353 8354 8355 8356 8357 8358 8359 8360 8361 8362 8362 8362 8363 8364\n",
            " 8365 8366 8366 8367 8368 8369 8369 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [17, 19, 26, 29, 39, 43]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353 8354\n",
            " 8355 8356 8357 8358 8358 8359 8359 8360 8361 8362 8363 8364 8365 8365\n",
            " 8366 8367 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376 8376 8377\n",
            " 8378 8379 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [10, 11, 12, 17, 19, 26]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8351 8351 8351\n",
            " 8352 8353 8354 8355 8355 8356 8356 8357 8358 8359 8360 8361 8362 8362\n",
            " 8363 8364 8365 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [5, 6, 21, 24, 27, 38]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8346 8346 8347 8348 8349 8350 8351 8352\n",
            " 8353 8354 8355 8356 8357 8358 8359 8360 8360 8361 8362 8362 8363 8364\n",
            " 8364 8365 8366 8367 8368 8369 8370 8371 8372 8373 8374 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [0, 9, 10, 25, 33, 39]\n",
            "result :  [8341 8341 8342 8343 8344 8345 8346 8347 8348 8349 8349 8349 8350 8351\n",
            " 8352 8353 8354 8355 8356 8357 8358 8359 8360 8361 8362 8363 8363 8364\n",
            " 8365 8366 8367 8368 8369 8370 8370 8371 8372 8373 8374 8375 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [4, 11, 22, 24, 27, 41]\n",
            "result :  [8341 8342 8343 8344 8345 8345 8346 8347 8348 8349 8350 8351 8351 8352\n",
            " 8353 8354 8355 8356 8357 8358 8359 8360 8361 8361 8362 8362 8363 8364\n",
            " 8364 8365 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376 8377\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [14, 19, 21, 38, 40, 41]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353 8354\n",
            " 8355 8355 8356 8357 8358 8359 8359 8360 8360 8361 8362 8363 8364 8365\n",
            " 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376 8376 8377 8377\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [1, 5, 11, 16, 21, 25]\n",
            "result :  [8341 8342 8342 8343 8344 8345 8345 8346 8347 8348 8349 8350 8350 8351\n",
            " 8352 8353 8354 8354 8355 8356 8357 8358 8358 8359 8360 8361 8361 8362\n",
            " 8363 8364 8365 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [12, 15, 16, 21, 27, 29]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353 8353\n",
            " 8354 8355 8355 8355 8356 8357 8358 8359 8359 8360 8361 8362 8363 8364\n",
            " 8364 8365 8365 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [12, 25, 30, 31, 40, 42]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353 8353\n",
            " 8354 8355 8356 8357 8358 8359 8360 8361 8362 8363 8364 8365 8365 8366\n",
            " 8367 8368 8369 8369 8369 8370 8371 8372 8373 8374 8375 8376 8377 8377\n",
            " 8378 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [1, 14, 15, 17, 21, 31]\n",
            "result :  [8341 8342 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353\n",
            " 8354 8354 8354 8355 8355 8356 8357 8358 8358 8359 8360 8361 8362 8363\n",
            " 8364 8365 8366 8367 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [8, 16, 19, 26, 34, 39]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8349 8350 8351 8352 8353\n",
            " 8354 8355 8356 8356 8357 8358 8358 8359 8360 8361 8362 8363 8364 8364\n",
            " 8365 8366 8367 8368 8369 8370 8371 8371 8372 8373 8374 8375 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [11, 13, 17, 31, 32, 34]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8352 8353\n",
            " 8353 8354 8355 8356 8356 8357 8358 8359 8360 8361 8362 8363 8364 8365\n",
            " 8366 8367 8368 8369 8369 8369 8370 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [14, 21, 26, 34, 35, 41]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353 8354\n",
            " 8355 8355 8356 8357 8358 8359 8360 8361 8361 8362 8363 8364 8365 8365\n",
            " 8366 8367 8368 8369 8370 8371 8372 8372 8372 8373 8374 8375 8376 8377\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [8, 13, 16, 28, 30, 41]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8349 8350 8351 8352 8353\n",
            " 8353 8354 8355 8355 8356 8357 8358 8359 8360 8361 8362 8363 8364 8365\n",
            " 8366 8366 8367 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376 8377\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [2, 9, 10, 16, 25, 42]\n",
            "result :  [8341 8342 8343 8343 8344 8345 8346 8347 8348 8349 8349 8349 8350 8351\n",
            " 8352 8353 8354 8354 8355 8356 8357 8358 8359 8360 8361 8362 8362 8363\n",
            " 8364 8365 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376 8377\n",
            " 8378 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [5, 18, 25, 30, 37, 43]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8346 8347 8348 8349 8350 8351 8352 8353\n",
            " 8354 8355 8356 8357 8358 8358 8359 8360 8361 8362 8363 8364 8364 8365\n",
            " 8366 8367 8368 8368 8369 8370 8371 8372 8373 8374 8374 8375 8376 8377\n",
            " 8378 8379 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [0, 2, 26, 32, 37, 40]\n",
            "result :  [8341 8341 8342 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352\n",
            " 8353 8354 8355 8356 8357 8358 8359 8360 8361 8362 8363 8364 8365 8365\n",
            " 8366 8367 8368 8369 8370 8370 8371 8372 8373 8374 8374 8375 8376 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [1, 17, 19, 22, 36, 42]\n",
            "result :  [8341 8342 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353\n",
            " 8354 8355 8356 8357 8357 8358 8358 8359 8360 8360 8361 8362 8363 8364\n",
            " 8365 8366 8367 8368 8369 8370 8371 8372 8373 8373 8374 8375 8376 8377\n",
            " 8378 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [3, 5, 16, 17, 18, 32]\n",
            "result :  [8341 8342 8343 8344 8344 8345 8345 8346 8347 8348 8349 8350 8351 8352\n",
            " 8353 8354 8355 8355 8355 8355 8356 8357 8358 8359 8360 8361 8362 8363\n",
            " 8364 8365 8366 8367 8368 8368 8369 8370 8371 8372 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [7, 19, 23, 28, 30, 38]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8348 8349 8350 8351 8352 8353\n",
            " 8354 8355 8356 8357 8358 8359 8359 8360 8361 8362 8362 8363 8364 8365\n",
            " 8366 8366 8367 8367 8368 8369 8370 8371 8372 8373 8374 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [1, 5, 13, 14, 40, 42]\n",
            "result :  [8341 8342 8342 8343 8344 8345 8345 8346 8347 8348 8349 8350 8351 8352\n",
            " 8352 8352 8353 8354 8355 8356 8357 8358 8359 8360 8361 8362 8363 8364\n",
            " 8365 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8376 8377 8377\n",
            " 8378 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [1, 17, 18, 37, 40, 43]\n",
            "result :  [8341 8342 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353\n",
            " 8354 8355 8356 8357 8357 8357 8358 8359 8360 8361 8362 8363 8364 8365\n",
            " 8366 8367 8368 8369 8370 8371 8372 8373 8374 8375 8375 8376 8377 8377\n",
            " 8378 8379 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [28, 29, 32, 34, 35, 37]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353 8354\n",
            " 8355 8356 8357 8358 8359 8360 8361 8362 8363 8364 8365 8366 8367 8368\n",
            " 8369 8369 8369 8370 8371 8371 8372 8372 8372 8373 8373 8374 8375 8376\n",
            " 8377 8378 8379 8380 8381 8382 8383 8384]\n",
            "these indexes will be added [12, 27, 32, 35, 37, 43]\n",
            "result :  [8341 8342 8343 8344 8345 8346 8347 8348 8349 8350 8351 8352 8353 8353\n",
            " 8354 8355 8356 8357 8358 8359 8360 8361 8362 8363 8364 8365 8366 8367\n",
            " 8367 8368 8369 8370 8371 8371 8372 8373 8373 8374 8374 8375 8376 8377\n",
            " 8378 8379 8379 8380 8381 8382 8383 8384]\n",
            "105 th video : hit the limit!\n",
            "118 th video : hit the limit!\n",
            "129 th video : hit the limit!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBmopfmij9kC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the networks inputs\n",
        "X_pre_train = split_in_blocks(X_np_train, n_steps)\n",
        "X_test = split_in_blocks(X_np_test, n_steps)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p84tjqbGu_CD",
        "colab_type": "text"
      },
      "source": [
        "##y_train, y_val, y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvQap_O9uQsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pre_train, y_test = get_y(augmentation_amount, own_added)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oem7uCiT4oEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_pre_train, y_pre_train, test_size = 0.3, random_state=64)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZzvdv1p48E-",
        "colab_type": "text"
      },
      "source": [
        "##Train it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11_6AztjHxYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#useful constant for training\n",
        "\n",
        "# Input Data \n",
        "n_hidden = 256 # Hidden layer num of features\n",
        "n_classes = 35\n",
        "learning_rate = 0.0007 #used if decaying_learning_rate set to False\n",
        "decay_rate = 0.02 #the base of the exponential in the decay\n",
        "lambda_loss_amount = 0.0015\n",
        "\n",
        "training_epochs = 100\n",
        "batch_size = 64"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV9P_Z-AkAG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "414022d2-eb60-455d-c3b1-6ea1c53898bb"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Input Data \n",
        "n_input = len(X_train[0][0])\n",
        "\n",
        "model = SLT_model.GRU_RNN2(n_input, n_hidden, n_classes, lambda_loss_amount, batch_size, n_steps)\n",
        "\n",
        "model.compile(\n",
        "   optimizer=optimizers.Adam(lr=learning_rate, decay=decay_rate),\n",
        "   metrics=['accuracy'],\n",
        "   loss='categorical_crossentropy'\n",
        ")\n",
        "\n",
        "y_train_one_hot = keras.utils.to_categorical(y_train, 35)\n",
        "y_val_one_hot = keras.utils.to_categorical(y_val, 35)\n",
        "y_test_one_hot = keras.utils.to_categorical(y_test, 35)\n",
        "\n",
        "train_size = X_train.shape[0] - X_train.shape[0] % batch_size\n",
        "val_size = X_val.shape[0] - X_val.shape[0] % batch_size\n",
        "test_size = X_test.shape[0] - X_test.shape[0] % batch_size\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15, min_delta=0.005)\n",
        "\n",
        "history = model.fit(\n",
        "   X_train[:train_size,:,:], \n",
        "   y_train_one_hot[:train_size,:],\n",
        "   epochs=training_epochs,\n",
        "   batch_size=batch_size,\n",
        "   validation_data=(X_val[:val_size,:,:], y_val_one_hot[:val_size,:]),\n",
        "   callbacks=[es]\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 19584 samples, validate on 8384 samples\n",
            "Epoch 1/100\n",
            "19584/19584 [==============================] - 62s 3ms/step - loss: 1.4201 - accuracy: 0.6124 - val_loss: 0.6618 - val_accuracy: 0.8424\n",
            "Epoch 2/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.5101 - accuracy: 0.8787 - val_loss: 0.3987 - val_accuracy: 0.9076\n",
            "Epoch 3/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.3571 - accuracy: 0.9106 - val_loss: 0.3139 - val_accuracy: 0.9176\n",
            "Epoch 4/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.2941 - accuracy: 0.9224 - val_loss: 0.2677 - val_accuracy: 0.9269\n",
            "Epoch 5/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.2562 - accuracy: 0.9322 - val_loss: 0.2379 - val_accuracy: 0.9339\n",
            "Epoch 6/100\n",
            "19584/19584 [==============================] - 56s 3ms/step - loss: 0.2321 - accuracy: 0.9383 - val_loss: 0.2163 - val_accuracy: 0.9359\n",
            "Epoch 7/100\n",
            "19584/19584 [==============================] - 56s 3ms/step - loss: 0.2164 - accuracy: 0.9410 - val_loss: 0.2040 - val_accuracy: 0.9444\n",
            "Epoch 8/100\n",
            "19584/19584 [==============================] - 56s 3ms/step - loss: 0.2030 - accuracy: 0.9453 - val_loss: 0.1959 - val_accuracy: 0.9408\n",
            "Epoch 9/100\n",
            "19584/19584 [==============================] - 56s 3ms/step - loss: 0.1934 - accuracy: 0.9453 - val_loss: 0.1875 - val_accuracy: 0.9473\n",
            "Epoch 10/100\n",
            "19584/19584 [==============================] - 56s 3ms/step - loss: 0.1865 - accuracy: 0.9466 - val_loss: 0.1787 - val_accuracy: 0.9456\n",
            "Epoch 11/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1814 - accuracy: 0.9459 - val_loss: 0.1751 - val_accuracy: 0.9485\n",
            "Epoch 12/100\n",
            "19584/19584 [==============================] - 56s 3ms/step - loss: 0.1765 - accuracy: 0.9478 - val_loss: 0.1718 - val_accuracy: 0.9487\n",
            "Epoch 13/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1728 - accuracy: 0.9488 - val_loss: 0.1691 - val_accuracy: 0.9433\n",
            "Epoch 14/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1689 - accuracy: 0.9483 - val_loss: 0.1663 - val_accuracy: 0.9480\n",
            "Epoch 15/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1653 - accuracy: 0.9491 - val_loss: 0.1632 - val_accuracy: 0.9450\n",
            "Epoch 16/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1627 - accuracy: 0.9500 - val_loss: 0.1603 - val_accuracy: 0.9445\n",
            "Epoch 17/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1607 - accuracy: 0.9494 - val_loss: 0.1583 - val_accuracy: 0.9461\n",
            "Epoch 18/100\n",
            "19584/19584 [==============================] - 56s 3ms/step - loss: 0.1597 - accuracy: 0.9502 - val_loss: 0.1556 - val_accuracy: 0.9479\n",
            "Epoch 19/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1577 - accuracy: 0.9499 - val_loss: 0.1539 - val_accuracy: 0.9474\n",
            "Epoch 20/100\n",
            "19584/19584 [==============================] - 56s 3ms/step - loss: 0.1551 - accuracy: 0.9516 - val_loss: 0.1571 - val_accuracy: 0.9461\n",
            "Epoch 21/100\n",
            "19584/19584 [==============================] - 56s 3ms/step - loss: 0.1541 - accuracy: 0.9509 - val_loss: 0.1529 - val_accuracy: 0.9475\n",
            "Epoch 22/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1529 - accuracy: 0.9521 - val_loss: 0.1531 - val_accuracy: 0.9458\n",
            "Epoch 23/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1522 - accuracy: 0.9493 - val_loss: 0.1512 - val_accuracy: 0.9478\n",
            "Epoch 24/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1503 - accuracy: 0.9521 - val_loss: 0.1499 - val_accuracy: 0.9469\n",
            "Epoch 25/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1493 - accuracy: 0.9516 - val_loss: 0.1475 - val_accuracy: 0.9475\n",
            "Epoch 26/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1489 - accuracy: 0.9516 - val_loss: 0.1475 - val_accuracy: 0.9476\n",
            "Epoch 27/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1469 - accuracy: 0.9529 - val_loss: 0.1465 - val_accuracy: 0.9499\n",
            "Epoch 28/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1465 - accuracy: 0.9515 - val_loss: 0.1456 - val_accuracy: 0.9501\n",
            "Epoch 29/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1459 - accuracy: 0.9517 - val_loss: 0.1452 - val_accuracy: 0.9504\n",
            "Epoch 30/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1455 - accuracy: 0.9523 - val_loss: 0.1446 - val_accuracy: 0.9486\n",
            "Epoch 31/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1444 - accuracy: 0.9517 - val_loss: 0.1429 - val_accuracy: 0.9492\n",
            "Epoch 32/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1438 - accuracy: 0.9519 - val_loss: 0.1423 - val_accuracy: 0.9512\n",
            "Epoch 33/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1433 - accuracy: 0.9526 - val_loss: 0.1409 - val_accuracy: 0.9503\n",
            "Epoch 34/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1421 - accuracy: 0.9541 - val_loss: 0.1417 - val_accuracy: 0.9511\n",
            "Epoch 35/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1419 - accuracy: 0.9534 - val_loss: 0.1415 - val_accuracy: 0.9522\n",
            "Epoch 36/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1414 - accuracy: 0.9540 - val_loss: 0.1417 - val_accuracy: 0.9511\n",
            "Epoch 37/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1412 - accuracy: 0.9542 - val_loss: 0.1397 - val_accuracy: 0.9534\n",
            "Epoch 38/100\n",
            "19584/19584 [==============================] - 59s 3ms/step - loss: 0.1402 - accuracy: 0.9529 - val_loss: 0.1404 - val_accuracy: 0.9525\n",
            "Epoch 39/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1391 - accuracy: 0.9551 - val_loss: 0.1385 - val_accuracy: 0.9518\n",
            "Epoch 40/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1390 - accuracy: 0.9532 - val_loss: 0.1389 - val_accuracy: 0.9522\n",
            "Epoch 41/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1386 - accuracy: 0.9552 - val_loss: 0.1382 - val_accuracy: 0.9526\n",
            "Epoch 42/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1389 - accuracy: 0.9538 - val_loss: 0.1380 - val_accuracy: 0.9535\n",
            "Epoch 43/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1384 - accuracy: 0.9547 - val_loss: 0.1369 - val_accuracy: 0.9549\n",
            "Epoch 44/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1374 - accuracy: 0.9540 - val_loss: 0.1376 - val_accuracy: 0.9522\n",
            "Epoch 45/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1372 - accuracy: 0.9553 - val_loss: 0.1365 - val_accuracy: 0.9531\n",
            "Epoch 46/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1375 - accuracy: 0.9533 - val_loss: 0.1386 - val_accuracy: 0.9516\n",
            "Epoch 47/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1363 - accuracy: 0.9539 - val_loss: 0.1359 - val_accuracy: 0.9542\n",
            "Epoch 48/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1361 - accuracy: 0.9549 - val_loss: 0.1355 - val_accuracy: 0.9521\n",
            "Epoch 49/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1362 - accuracy: 0.9548 - val_loss: 0.1350 - val_accuracy: 0.9541\n",
            "Epoch 50/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1365 - accuracy: 0.9550 - val_loss: 0.1353 - val_accuracy: 0.9521\n",
            "Epoch 51/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1359 - accuracy: 0.9540 - val_loss: 0.1352 - val_accuracy: 0.9536\n",
            "Epoch 52/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1353 - accuracy: 0.9552 - val_loss: 0.1353 - val_accuracy: 0.9543\n",
            "Epoch 53/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1348 - accuracy: 0.9560 - val_loss: 0.1346 - val_accuracy: 0.9526\n",
            "Epoch 54/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1352 - accuracy: 0.9543 - val_loss: 0.1336 - val_accuracy: 0.9536\n",
            "Epoch 55/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1344 - accuracy: 0.9547 - val_loss: 0.1347 - val_accuracy: 0.9537\n",
            "Epoch 56/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1344 - accuracy: 0.9537 - val_loss: 0.1334 - val_accuracy: 0.9532\n",
            "Epoch 57/100\n",
            "19584/19584 [==============================] - 58s 3ms/step - loss: 0.1339 - accuracy: 0.9545 - val_loss: 0.1345 - val_accuracy: 0.9521\n",
            "Epoch 58/100\n",
            "19584/19584 [==============================] - 57s 3ms/step - loss: 0.1337 - accuracy: 0.9551 - val_loss: 0.1341 - val_accuracy: 0.9534\n",
            "Epoch 00058: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqJtxB9wOrvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "e59a47a8-31eb-4536-d37a-74b6b6c449d6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, 'b', label=\"Validation acc\")\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation loss\")\n",
        "plt.title(\"Training and Validation loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dHToANnHMYB",
        "colab_type": "text"
      },
      "source": [
        "##Test it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rx4uVPNWo8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_one_hot = keras.utils.to_categorical(y_test, 35)\n",
        "test_size = X_test.shape[0] - X_test.shape[0] % batch_size"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0Hxx1j6Wzbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc83ded8-3550-427f-adee-8751415e4ac0"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "import operator\n",
        "\n",
        "model_path = \"/content/drive/My Drive/KSL-translator/model/\"\n",
        "\n",
        "json_file = open(model_path + 'SLT-model-001-001.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(model_path + \"SLT-model-001-001.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNyA_1SzCXa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "09af63e7-1c36-483d-c4f6-a946a9bc935a"
      },
      "source": [
        "model.compile(\n",
        "   optimizer=optimizers.Adam(lr=learning_rate, decay=decay_rate),\n",
        "   metrics=['accuracy'],\n",
        "   loss='categorical_crossentropy'\n",
        ")\n",
        "\n",
        "loss_and_metrics = model.evaluate(x=X_test[:test_size,:,:], y=y_test_one_hot[:test_size,:], batch_size=batch_size)\n",
        "\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6976/6976 [==============================] - 5s 690us/step\n",
            "[1.3274937626145302, 0.6989678740501404]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlFsr54FHaKK",
        "colab_type": "text"
      },
      "source": [
        "##Save the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pay5ETnGRXcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/My Drive/Capstone/model/SLT-model-001.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"/content/drive/My Drive/Capstone/model/SLT-model-001.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnJjpxzZHnGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}